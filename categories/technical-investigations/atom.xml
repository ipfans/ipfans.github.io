<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Technical Investigations on ipfans's Blog</title><link>https://www.4async.com/categories/technical-investigations/</link><description>Recent content in Technical Investigations on ipfans's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 06 Jul 2021 11:41:00 +0000</lastBuildDate><atom:link href="https://www.4async.com/categories/technical-investigations/atom.xml" rel="self" type="application/rss+xml"/><item><title>什么是事件建模Event Modeling?</title><link>https://www.4async.com/2021/07/introducing-event-modeling/</link><pubDate>Tue, 06 Jul 2021 11:41:00 +0000</pubDate><guid>https://www.4async.com/2021/07/introducing-event-modeling/</guid><description>基本概念 事件建模（Event Modeling）是一种描述系统的方法，展示信息如何随时间变化的例子。具体来说，这种方式省略了瞬息万变的细节，而着眼于在任何特定的时间点上的持久化存储和用户所见数据的变化。这些时间轴上的事件，构成了对系统的描述。
近年来，很多系统使用事件通过事件存储数据库或者使用特定方式使用常规数据库构建了状态和信息传播的模块。然而，大多数方法仍然依赖于通过SQL数据库、文档数据库或者其他技术实现严格意义上的当前时间点信息的视图。
对很多系统而言，特别是对于非小型系统而言，随着系统复杂性的增加，变更成本将会随着时间的推移难度指数级上升。与现有的设计和建模方式对比，事件建模可以在短时间内创建一个基础蓝图，将返工工作量降到最低。
从过去谈起 讲故事自古以来就是人类能够将知识传递给后代的方法，它在很大程度上依赖于我们如何存储记忆-无论是逻辑的、视觉的、听觉的还是其他的。这一点很重要，因为这与信息系统的构建方式有相似之处。 用具体的例子说明某物应该如何工作是一种常见的方式。这种方式可以在软件开发的成功实践中看到，如行为驱动开发。这种方式很有效，因为我们通过故事来沟通更有效。将它和讲故事联系在一起，是一种保持社会信息的方式。我们的大脑是为它而建的，而不是为流程图和其他格式而建的。 而事件建模模型就是遵循这种讲故事模式而建立的产品建模方式。
事件建模模式
时间线是最好描述故事主线的方式，对我们的系统而言，时间线也是描述我们系统核心部分概念的重要组成部分。我们可以通过在一条时间线上，系统从开始到结束，在没有分支情况下应该做什么方式展示我们系统的一部分功能。这就是一个典型的事件模型的组成。我们可以用这种方式跟踪所有UI界面中字段值如何存储和如何展示的。比如在上面的示例图中，我们使用了3种不同模块的内容和传统的线框模型就展示了整个系统的模型。但是简单性是我们重要的一个目标，因此我们只依赖于4种模式构建这种模型图。
保持简单性 当我们想采用某些做法或流程来帮助彼此理解和沟通时，它与个人为熟练掌握这些方法而进行的学习量成反比。换句话说，如果我们可以更快的掌握一个名叫X的方法时，我们就可以更好的通过这种方式进行知识分享和互动；反之，无论这种方法多么好，昂贵的学习成本总会搞砸一切。
当一本书是团队中的必读书目时，每个人都会说他们读过；但事实上只有一半的人会真正读过；这些真正读过的人中一半的人会声称他们理解了这本书；而这些声称理解的人中只有一半的人真正的理解了这本书；而这些真正理解了这本书的人只有一半的人能够使用它。
这就是为什么使用3个模块和基于2个想法的4种模式进行事件建模。因为这只需要几分钟就可以将所有的东西向所有人解释清楚。其他的学习则可以在实践中进行。即便理解出现了不足和错误，也可以很快在实践中得到纠正。
事件 假设我们想为连锁酒店设计一个酒店网站，让我们的客户可以在线预订房间，并让我们安排清洁和任何其他酒店问题。 我们可以显示在该业务的年度时间线上存储了哪些事件。 我们可以假装我们已经有了这个系统，然后问自己随着时间的推移存储了哪些事件。
线框图 让我们看一下在图片的最上面的部分的第一个模块。为了让讲故事这个事情更加可视化，我们可以在顶部显示功能的线框图或者网页模拟图。这也可以被具象化为具体的泳道图，以方便不同的人（也可以是系统）与我们的系统进行互动。这里一些自动化的内容可以用齿轮表示，同时说明系统正在做什么。通过这种方式，我们可以非常容易的展示出系统需要实现的功能列表，执行流程和项目完成标记。这里的图是示例了一个酒店的预订、支付和通知系统的过程，我们可以重点关注一下所有相关高亮显示的内容。
借助这个模块，我们可以很方便的和设计师一起沟通设计系统，当然，这里需要注意在设计中，两个重要的内容需要添加到整个设计中：用户所拥有的权限和用户可以获取的信息。
命令 大多数信息系统必须给用户一种影响系统的状态的能力，而这种能力就是命令。在我们的例子中，我们必须允许房间预订改变系统状态，这样我们就不会发生超额预订情况。当那个人在未来的预订日期到达时，他们就有一个为他们准备的房间。
改变系统状态的意图会被封装在一个命令中。相对于简单地将表单数据保存到数据库中的一个表中，这可以让我们以非技术性的方式来显示意图，同时允许任何实现 - 尽管我们可以看到某些方法更具优势。
从UI和UX的角度来看，这就是一个&amp;quot;命令响应式用户界面&amp;quot;，对帮助制作可组合的UI大有帮助。使用这种模式，从技术和商业的角度来看，交易的界限就更清楚了。以酒店入住为例，酒店的客人要么登记成功，要么没有。
当命令成功的前提条件有细微的差别时，它们会在&amp;quot;Given-When-Then&amp;quot;风格的描述方式中进行阐述。这种方式也是行为测试模式惯用的描述方式，也是一种成功的讲述故事的方式。实际执行过程中，可能会有几个这样的故事来说明一个命令如何能成功执行和不能成功执行。
这里我们可以用一个例子来描述一下：
Given：我们已经注册并添加了一个支付方式
When：我们试图预订一个房间
Then：一个房间被预订了
这种描述方式也通常被叫做“安排、行动、断言”，在UI/UX的世界中，也被称为“情景、统计、价值”。 在图中我们也可以发现，所有的命令都是用蓝色进行标记的。
视图（或者叫读模型） 任何信息系统的一个重要能力是将系统中保存的状态告知用户。我们的酒店客人需要知道他们感兴趣的某些类型的房间在哪一天可以入住。这通常有很多种情况，需要支持信息系统的多个模型。
随着这些新事件的存储，系统中的视图也会一直变化。在我们的酒店系统中，这个日历视图随着影响库存的新事件的发生而被更新。其他视图中清洁团队可以在客户离店事件存储后在其他视图中看到房间已经可以被清理了。
指定视图的行为方式与我们指定接受命令的方式非常相似，但有一处不同。视图是被动的，并且不能在事件被存储到系统中之后撤销事件。
举个例子：
Given：酒店设置了12间海景房，海景房从4月4日到12日被预订
Then：日历上应该显示除4月4日到12日以外的所有海景房的日期
从上面图中我们也可以注意到，所有的读都是用绿色进行标记的。
集成 我们刚刚介绍了描述大多数系统所需的 4 种模式中的前 2 种模式。 系统可以从其他系统获取信息并且将信息发送到其他系统。 强迫这 2 个模式成为前 2 个模式的扩展并共享相同的空间是很诱人的选择。 然而这会让交流变得更加困难，因为它们没有人类可见的方面，并且需要一些更高级别的模式。</description></item><item><title>构建属于你自己的dapr绑定组件</title><link>https://www.4async.com/2021/05/building-your-own-dapr-binding/</link><pubDate>Sat, 15 May 2021 18:38:00 +0000</pubDate><guid>https://www.4async.com/2021/05/building-your-own-dapr-binding/</guid><description>在上一篇文章中，吐槽了拖延症的危害，因此这次我来分享一下我最新推送到dapr的最新的一个新的绑定组件，通过这个来看一下如何实现自己的绑定组件。
文中提到的PR可以在 dapr/components-contrib#872 查看对应的具体代码。
什么是 dapr 的绑定组件？ 在dapr中，绑定是用于使用外部系统功能（比如事件或者接口）的扩展组件。它的优势在于：
免除连接到消息传递系统(如队列和消息总线)并进行轮询的复杂性； 聚焦于业务逻辑，而不是如何与系统交互的实现细节； 使代码不受 SDK 或库的跟踪； 处理重试和故障恢复； 在运行时在绑定之间切换； 构建具有特定于环境的绑定的可移植应用程序，不需要进行代码更改； 在官方文档中，也提到了一个具体的例子：以twilio发送短信为例，一般开发过程中应用程序需要依赖Twilio SDK才可以实现功能，但是借助绑定组件，你可以将SDK的绑定转移至dapr程序领域内，在本身应用程序中不再绑定对应的SDK，不用担心未来SDK过期或者变更带来的重复工作（仅需要更新dapr即可）。
根据订阅的进出方向，绑定组件也分为输入绑定和输出绑定。这些绑定均是通过yaml文件描述类型和元数据，通过HTTP/gRPC进行调用。
如何实现自己的绑定组件？ 官方例子中提供了一个基础的介绍，上一节中我们也提到了在程序中，根据进出方向可以把绑定组件分为输出绑定和输入绑定。你可以通过官方教程中的例子提供查看：
在这个例子用，你可以看到，根据方向吧dapr发布消息到Kafka作为输出组件，把Kafka读取消息到dapr作为输入组件。
绑定的声明yaml文件的规范则如下：
apiVersion: dapr.io/v1alpha1 kind: Component metadata: name: &amp;lt;NAME&amp;gt; namespace: &amp;lt;NAMESPACE&amp;gt; spec: type: bindings.&amp;lt;TYPE&amp;gt; version: v1 metadata: - name: &amp;lt;NAME&amp;gt; value: &amp;lt;VALUE&amp;gt; 其中metadata.name则是绑定置名称，spec.metadata.name和spec.metadata.value则是配置的属性和对应值。这个值我们可以通过实现接口InputBinding或者OutputBinding实现输入绑定和输出绑定.
type InputBinding interface { Init(metadata Metadata) error Read(handler func(*ReadResponse) ([]byte, error)) error } type OutputBinding interface { Init(metadata Metadata) error Invoke(req *InvokeRequest) (*InvokeResponse, error) Operations() []OperationKind } 接下来需要实现一个生成对象的方法，比如说我们需要实现一个飞书推送Webhook的绑定组件，则可以：</description></item><item><title>构建属于你自己的dapr服务发现</title><link>https://www.4async.com/2021/05/building-your-own-dapr-service-discovery/</link><pubDate>Sat, 08 May 2021 18:38:00 +0000</pubDate><guid>https://www.4async.com/2021/05/building-your-own-dapr-service-discovery/</guid><description>写在最前: 这篇文章其实算是马后炮了，因为一直拖延症的问题，顺带过了一个五一假期，结果发现已经有社区贡献者提供了Consul的服务发现实现，于是本来写了一半的文章只能进行调整了。拖延症害人啊！几个草稿的文章看来要尽快赶出来了🤦‍♂️
在上一篇文章中，我其实遗留了一个问题：如何定义dapr的服务发现呢？其实在后面阅读dapr的源码之后也前一篇文章的评论中提到了答案：目前dapr提供了内置两种服务发现模式：K8s模式和用于独立部署的mDNS模式。mDNS模式在某些网络环境下可能存在问题（比如跨机房），不过没有关系，dapr同时提供了可扩展能力，可以通过定义自主的服务发现能力扩展dapr的边界。
从 NameResolution 到 Resolver 接口 在 pkg/components/nameresolution/registry.go 文件中，dapr定义了一个 NameResolution 结构体用于服务注册和发现：
type ( // NameResolution is a name resolution component definition. NameResolution struct { Name string FactoryMethod func() nr.Resolver } // Registry handles registering and creating name resolution components. Registry interface { Register(components ...NameResolution) Create(name, version string) (nr.Resolver, error) } nameResolutionRegistry struct { resolvers map[string]func() nr.Resolver } ) 其中真正的服务解析则是依靠 components-contrib 中实现了 Resolver 接口的具体实现执行。
// Resolver is the interface of name resolver.</description></item><item><title>在非容器(集群)环境下运行dapr</title><link>https://www.4async.com/2021/03/2021-03-11-running-dapr-without-container/</link><pubDate>Thu, 11 Mar 2021 18:38:00 +0000</pubDate><guid>https://www.4async.com/2021/03/2021-03-11-running-dapr-without-container/</guid><description>前一段时间一直关注的dapr正式发布了v1.0版本(实际上本文发布时还更新了v1.0.1)，代表dapr在某些程度上进入稳定状态，可以尝试在实际中进行运用。作为我一直关注的项目，在第一时间中进行了尝试，并试图引入实际项目中，本文则是针对这些的一些先期测试内容.
什么是dapr？ dapr最早是由微软开源的(不愧是你)，一个可移植的、事件驱动的程序运行时，它使任何开发者都能轻松地构建运行在云和边缘的弹性、无状态/有状态的应用程序，并且可以灵活支持多种开发语言。换而言之，在我看来，dapr可以作为一个serverless落地方案看待和处理，对程序而言，只关注提供的store和消息队列接口，无需关心架构层面更多内容。
overview
不过在官方的示例教程中，使用的环境为容器环境部署和管理dapr。实际上，除了在容器环境或者容器集群环境下，dapr可以配置为在本地机器上以自托管模式运行。
本地安装 dapr安装可以通过官方的dapr-cli实现，dapr-cli可以通过一键安装命令快速安装：
# wget -q https://raw.githubusercontent.com/dapr/cli/master/install/install.sh -O - | /bin/bash Your system is linux_amd64 Dapr CLI is detected: main: line 86: 43656 Segmentation fault $DAPR_CLI_FILE --version Reinstalling Dapr CLI - /usr/local/bin/dapr... Getting the latest Dapr CLI... Installing v1.0.0 Dapr CLI... Downloading https://github.com/dapr/cli/releases/download/v1.0.0/dapr_linux_amd64.tar.gz ... dapr installed into /usr/local/bin successfully. CLI version: 1.0.0 Runtime version: n/a To get started with Dapr, please visit https://docs.dapr.io/getting-started/ 可以通过输入dapr命令确认dapr-cli程序是否被正常安装成功。</description></item><item><title>NATS-Server(JetStream)和NATS Streaming Server对比</title><link>https://www.4async.com/2021/03/2021-03-02-nats-server-usage/</link><pubDate>Tue, 02 Mar 2021 18:38:00 +0000</pubDate><guid>https://www.4async.com/2021/03/2021-03-02-nats-server-usage/</guid><description>在我吐槽了无数次之后，NATS JetStream终于结束了beta阶段正式进入RC阶段。终于官方也在最近刚刚正式回复了我正式版本在处理几个问题之后就会正式发布。那么在这个比较重要的NATS-Server特性发布之际聊一下NATS产品本身区别和新特性的使用，还有更多的潜在的区别。
概念区分：NATS-Server / NATS Streaming Server / NATS JetStream NATS-Server NATS-Server（或者叫nats）是一个开源的、云原生的、高性能的消息传递系统，是NATS的最基础的产品。它的核心是一个发布/订阅（Pub/Sub）系统，客户端可以在不同集群中的服务间nats进行通讯，而不需要关注具体的消息在哪个服务上。换而言之，客户端可以在任意一个集群的服务端上发布消息，同时在任意集群客户端上尝试读取消息。在官方与其他同类消息队列产品功能对比中，我们也可以管窥一下产品的功能列表。nats支持多流多服务进行pub/sub，负载均衡，保障消息最多/最少一次送达，多租户和用户认证等功能。虽然看上去优点很多，但是nats不是一个应用很广的消息队列的重要原因是，它缺少了一些对消息队列而言很最重要的产品特性，比如持久化支持，比如消息确保一次送达。这意味着当你的消息发送出去之后，你的消息是在处理过程中可能丢失的，甚至是可能送达不到的。
NATS Streaming Server NATS Streaming Server（或者叫stan）是用于尝试解决上面提到的nats的已存在问题的。stan添加了持久化功能和消息送达策略支持。stan中自带了nats服务端，但是在使用过程中，nats和stan不能进行混用。在官方文档中，是这么描述stan和nats之间的关系的：
NATS客户端和NATS Streaming Server客户端之间不能相互交换数据。也就是说，如果一个NATS Streaming Server客户端在foo上发布消息，在同一主题上订阅的NATS客户端将不会收到消息。NATS Streaming Server消息是由protobuf组成的NATS消息。NATS Streaming Server要向生产者发送ACK，并接收消费者的ACK。如果与NATS客户端自由交换消息，就会引起问题。
stan的具体架构如下图：
但是stan虽然提供了持久化和消息传递策略支持，但是在架构设计上却出现了问题，导致在最开始设计时遗留了很多问题，比如当你确定stan集群是固定的不能无限制水平扩容(#999)，比如不支持多租户功能(#1122)，比如客户端无法主动拉取消息只能被推送等等
NATS JetStream NATS JetStream（或者叫JetStream）是NATS基于Raft算法实现的最新的架构设计尝试解决上述问题的新方案。在区别于原有的stan功能上，提供了新的持久化功能和消息送达策略，同时支持水平扩容。同时，新的JetStream也为大消息做了一些优化，不再将这特性功能作为nats的客户端存在而是嵌入NATS Server中作为其中的一个功能存在。也就是说，如果在对这几项技术进行选择时，JetStream应该是最应该被选择的方案。更多详细情况具体可以查看官方的指导文档。
NATS JetStream使用 理论介绍过了，接下来说说实际使用的事情。现在JetStream还是RC阶段，
编译和启动客户端 下载nats-server源码，解压之后执行：
cd nats-server-master go build -o nats-server -ldflags=&amp;quot;-s -w -buildid=&amp;quot; . ./nats-server -js 这样就可以启动一个支持JetStream功能的服务端了。
[54738] 2021/03/02 18:27:02.605197 [INF] Starting nats-server [54738] 2021/03/02 18:27:02.605236 [INF] Version: 2.2.0-RC.2 [54738] 2021/03/02 18:27:02.</description></item><item><title>OpenTelemetry入门</title><link>https://www.4async.com/2020/03/2020-03-31-intro-opentelemetry/</link><pubDate>Tue, 31 Mar 2020 11:10:00 +0000</pubDate><guid>https://www.4async.com/2020/03/2020-03-31-intro-opentelemetry/</guid><description>&lt;p>今天早些时候，&lt;a class="link" href="https://opentelemetry.io/" target="_blank" rel="noopener"
>OpenTelemetry&lt;/a>正式&lt;a class="link" href="https://medium.com/opentelemetry/opentelemetry-is-officially-in-beta-352fa859db10" target="_blank" rel="noopener"
>进入Beta版本阶段&lt;/a>，这标志着OpenTelemetry的基本模型已经正式确定，可以开始将OpenTelemetry集成到应用程序和客户端库中，以捕获应用程序级指标和分布式跟踪。&lt;/p></description></item><item><title>利用Stub File标注Python文件</title><link>https://www.4async.com/2019/01/2019-01-28-python-typing-with-stub-files/</link><pubDate>Tue, 29 Jan 2019 14:30:00 +0000</pubDate><guid>https://www.4async.com/2019/01/2019-01-28-python-typing-with-stub-files/</guid><description>&lt;p>在升级到&lt;code>Python 3.5+&lt;/code>版本之后，最大的项目管理优化来自于&lt;a class="link" href="https://www.python.org/dev/peps/pep-0484/" target="_blank" rel="noopener"
>&lt;code>PEP-484 Type Hint&lt;/code>&lt;/a>的引入。借助&lt;code>Type Hint&lt;/code>，我们可以进一步提升&lt;code>Python&lt;/code>代码的类型标注，保障在重构过程中避免出现一些低级失误。&lt;/p>
&lt;p>我们可以通过高版本&lt;code>Python&lt;/code>新加的新语法启用这项特性，然后通过&lt;code>mypy&lt;/code>等工具检查：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">greeting&lt;/span>(name: str) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> str:
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#e6db74">&amp;#39;Hello &amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> name
&lt;/code>&lt;/pre>&lt;/div>&lt;p>然而，在实际实践过程中，也往往存在一些问题，这些问题来自于很多方面：&lt;/p></description></item><item><title>聊聊新的Go语言错误处理方案</title><link>https://www.4async.com/2019/01/2019-01-25-go-new-xerrors/</link><pubDate>Fri, 25 Jan 2019 23:20:00 +0000</pubDate><guid>https://www.4async.com/2019/01/2019-01-25-go-new-xerrors/</guid><description>今天早些时候，golang/x/exp中默默的更新了一个名曰xerrors的包，这个包和同样处于golang/x/exp下的另一个名叫errors的包名字十分相似，就连介绍也都一致：
Package errors implements functions to manipulate errors. This package implements the Go 2 draft designs for error inspection and printing 从目前的情况来看，基本上错误的处理形式基本已经定型，处理方式则是类似于之前的另一个github.com/pkg/errors包，但是具体细节不尽相同。
如何处理error？ 在之前介绍文章中提到过github.com/pkg/errors包的设计思路，那么在Go团队的实现中，这种思路也得到了继承。先从一个小例子开始：
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;golang.org/x/exp/xerrors&amp;#34; ) func raiseError() error { return xerrors.New(&amp;#34;a new error&amp;#34;) } func main() { err := xerrors.Errorf(&amp;#34;raiseError: %w&amp;#34;, raiseError()) fmt.Println(err) } 输出结果：
raiseError: a new error 看起来非常类似于之前github.com/pkg/errors的显示内容。而其中xerrors.Errorf则充当了之前errors.Wrap的功能。 其中值得一提的是%w，这个用于包装错误，后续验证错误中也会用到其中的值。
同时，这个包中也包含了几个非常有用的辅助函数，分别是：验证错误类型方法Is、错误类型转换方法As、错误关系链解除方法Opaque和提取内层错误方法Unwrap。我们可以用一个简单的演示来说明这种关系：
var ( ErrBase = xerrors.New(&amp;#34;a new error&amp;#34;) ) func main() { err := xerrors.</description></item><item><title>Consul平滑升级的一点建议</title><link>https://www.4async.com/2018/05/2018-05-10-consul-graceful-stop/</link><pubDate>Thu, 10 May 2018 15:20:00 +0000</pubDate><guid>https://www.4async.com/2018/05/2018-05-10-consul-graceful-stop/</guid><description>我们从 Consul 0.6.x 版本开始使用，中间也遇到的一些各种各样的问题，比较常见的操作问题就是 consul 的升级问题（比如解决 BUG，早期 Consul 的 BUG 也遇到了好几个）。
平滑升级时，我们常见的方式一般为替换 consul 可执行文件，然后执行 Graceful 重启
常见 Consul 的 Graceful leave 的方法有以下两种：
发送 SIGINT 信号至 Consul； 连接要升级的 consul，使用命令 consul leave 发送离开命令； 这两种方式都会让该节点主动退出集群并结束进程，如下：
[INFO] agent: Caught signal: terminated [INFO] agent: Graceful shutdown disabled. Exiting [INFO] agent: Requesting shutdown [INFO] consul: shutting down server [WARN] serf: Shutdown without a Leave [ERR] agent: Coordinate update error: No cluster leader [ERR] agent: failed to sync remote state: No cluster leader [WARN] serf: Shutdown without a Leave [INFO] manager: shutting down [INFO] agent: consul server down [INFO] agent: shutdown complete [INFO] agent: Stopping DNS server 10.</description></item><item><title>OSX 下安装 face_recognition</title><link>https://www.4async.com/2017/08/2017-08-02-install-face-recognition-on-osx/</link><pubDate>Wed, 02 Aug 2017 18:30:00 +0000</pubDate><guid>https://www.4async.com/2017/08/2017-08-02-install-face-recognition-on-osx/</guid><description>face_recognition 是一个热门的人脸识别库，常年占据 Github Trending Python 子类的 Top10。
在官方文档中，介绍安装 face_recognition 步骤非常简单，只需要执行 pip install face_recognition 就可以了，实际在安装过程中 face_recognition 有一些非 Python 依赖，需要单独安装，本文就对内容进行一个简单介绍，权作记录，方便大家手动安装时提前规避。文章基于 OSX 10.12.6+pyenv+python3.6.2 介绍。
问题在哪里？ face_recognition 的依赖大部分都比较好安装，只有一个库例外，那就是 dlib 这个依赖。这个依赖需要安装 boost 和 boost-python 两个非 Python 依赖。
安装 Boost 和 boost-python 这两个库可以通过 Homebrew 快速安装，使用如下命令进行安装：
brew install boost brew install boost-python --with-python3 需要注意的是，如果是 Python3 使用，需要额外参数，使用源码编译安装。如果使用 Python2 可以使用 Homebrew 的预编译包。
确认 Python dlib 要求 Python 编译时使用 --enable-shared 参数编译，默认情况下，pyenv 未启用该参数，因此编译需要使用下面参数进行 Python 重新编译
PYTHON_CONFIGURE_OPTS=&amp;quot;--with-dtrace --enable-shared&amp;quot; pyenv install 3.6.2 前面一个参数是我一直编译 Python 3.</description></item><item><title>gRPC 调用超时控制</title><link>https://www.4async.com/2017/04/2017-05-19-grpc-call-timeout/</link><pubDate>Thu, 06 Apr 2017 18:00:00 +0000</pubDate><guid>https://www.4async.com/2017/04/2017-05-19-grpc-call-timeout/</guid><description>我们在进行服务间调用时广泛采用 gRPC 作为主要的调用协议，借助 gRPC 的模块化与语言无关的特性，可以在我们拓展多语言模块之间提供更好的支持。但是我们在使用 gRPC 之中也出现了一些问题，这些问题会做一些记录，希望可以与大家一起沟通与交流。
某日，我们的客服反馈，我们的基础设施操作工具出现了长时间无响应的问题。该问题出现在我们对某些设备进行 OTA 升级时，操作长时间无返回，与之前预期的 10 秒内返回存在较大出入。经过我们的工程师分析，我们发现在 gRPC 处理过程中，我们的操作工具通过 gRPC 调用远程服务端接口时，接口长时间没有返回结果。
我们首先怀疑是 gRPC 调用过程中出现了连接问题。gRPC 过程中可能由于多种原因导致连接断开或者服务器无法连接。在调用 gRPC 方法过程中，我们可以通过 FailFast(true) 方式进行快速失败。实际上，这个值默认情况下为 true。
那么接下来我们就需要从调用从使用角度上寻找问题。我们使用过程中默许服务端在处理某些操作时进行较长时间操作（如长时间操作），但是从客户端角度而言，部分操作正常情况下我们是希望可以在有预定特定环境下达到某些时间仍旧未返回结果可以标记为结果失败。这样就需要通过 gRPC 的机制进行调控。由于目前我们的接口很多情况下调用接口实际为硬件接口，因此，我们采用通过控制 gRPC 客户端接口超时的方法控制。
在 gRPC 中，提供了 MethodConfig 用于控制每个方法的超时时间，这样可以对不同的 RPC 方法设置超时。
下面，我们用 官方的 gRPC 示例 演示如何进行调用超时控制。
首先，我们在 examples/helloworld/greeter_server/main.go 中的 SayHello 中添加一个长时间操作模拟：time.Sleep(10*time.Second)。
这时，如果我们需要客户端在 5 秒以内返回结果，应该如何操作呢？
那么我们修改 examples/helloworld/greeter_client/main.go 中的 main，添加超时处理内容：
func main() { // Set up method timeout configure. var wg sync.WaitGroup wg.Add(1) ch := make(chan grpc.</description></item><item><title>traefik 简介</title><link>https://www.4async.com/2016/08/2016-08-01-introduce-traefik-load-balance/</link><pubDate>Mon, 01 Aug 2016 11:00:00 +0000</pubDate><guid>https://www.4async.com/2016/08/2016-08-01-introduce-traefik-load-balance/</guid><description>traefik(https://traefik.io/) 是一款开源的反向代理与负载均衡工具。它最大的优点是能够与常见的微服务系统直接整合，可以实现自动化动态配置。目前支持 Docker, Swarm, Mesos/Marathon, Mesos, Kubernetes, Consul, Etcd, Zookeeper, BoltDB, Rest API 等等后端模型。
traefik 的具体模型如下： traefik
为什么选择 traefik？ 事实上在之前我对 LB 的选择一直更倾向于使用 HAProxy。但是选择 traefik 主要是有以下特点让我们决定使用：
Golang 编写，单文件部署，与系统无关，同时也提供小尺寸 Docker 镜像。 支持 Docker/Etcd 后端，天然连接我们的微服务集群。 内置 Web UI，管理相对方便。 自动配置 ACME(Let&amp;rsquo;s Encrypt) 证书功能。 性能尚可，我们也没有到压榨 LB 性能的阶段，易用性更重要。 除了这些以外，traefik 还有以下特点：
Restful API 支持。 支持后端健康状态检查，根据状态自动配置。 支持动态加载配置文件和 graceful 重启。 支持 WebSocket 和 HTTP/2。 除了上面提到的微服务化集群支持，一些 AB 测试阶段也可以通过 frontend 的路由特性进行动态分配，当然这些对 HAProxy 等软件都是标准支持的。
traefik 的配置 traefik 支持的配置方式支持文件方式进行配置，这个也是比较常见的配置方式，我们这里简单介绍一下。</description></item><item><title>利用 Type Hint 提升 Python 程序开发效率</title><link>https://www.4async.com/2016/07/2016-07-13-type-hint-improve-python-programming/</link><pubDate>Wed, 13 Jul 2016 20:00:00 +0000</pubDate><guid>https://www.4async.com/2016/07/2016-07-13-type-hint-improve-python-programming/</guid><description>Type Hint（或者叫做 PEP-484）提供了一种针对 Python 程序的类型标注标准。
为什么使用 Type Hint？对于动态语言而言，常常出现的情况是当你写了一段代码后，隔段时间你可能忘记这个方法的原型是什么样子的了，你也不清楚具体应该传入什么类型的参数，这样往往需要你去阅读代码才能定义每个类型具体是什么。或者当你使用一个文档并不是特别完全的第三方库，你不知道这个库应该如何使用，这都会很痛苦。
现在，借助 Type Hint，你可以实现：
实现类型检查，防止运行时出现的类型不符合情况。 作为文档附加属性，方便开发者调用时传入传出的参数类型。 提升 IDE 的检查机制，在智能提示时更快给出提示和类型检查结果。 实现这个过程中，你需要使用 Python 3.5+ 中提供的新模块 typing。值得注意的是，这个改动并不会影响程序运行，仅仅是为了方便类型检查器实现的。
Type Hint 类型检查器 目前，比如 JetBrains 家的 PyCharm 已经支持 Type Hint 语法检查功能，如果你使用了这个 IDE，可以通过 IDE 功能进行实现。如果你像我一样，使用了 SublimeText 编辑器，那么第三方工具 mypy 可以帮助到你。AnacondaST3 最近要发布的 2.0 版本也内置了 mypy 功能的支持，具体的进度可以看一下 这个 issue。一些其它的 Python 工具 (比如 代码提示工具 jedi 0.10+) 也支持了 Type Hint 功能。
从简单的例子开始 从简单的例子开始，我们先从一个简单的程序开始，运行环境为 Python 3.5.2，使用 mypy 工具进行检查。
首先通过 pip install mypy-lang 命令安装 mypy 工具。注意是 mypy-lang，之所以是这样，是因为在 pypi 里 mypy 这个名字已经被占用掉了。</description></item><item><title>CoreOS 折腾笔记（三）了解 Etcd</title><link>https://www.4async.com/2016/05/2016-05-31-learning-coreos-part3/</link><pubDate>Tue, 31 May 2016 09:13:00 +0000</pubDate><guid>https://www.4async.com/2016/05/2016-05-31-learning-coreos-part3/</guid><description>服务发现是微服务化架构中重要的一环，服务的配置信息需要有一种可靠高效的发现机制，保证服务上线时可以及时被使用，服务失效中断时可以及时切走。服务发现工具 Etcd 就是为了这种需求开发的。
什么是 Etcd？ Etcd 是一个分布式 KV 数据库，通过将数据分散存储在多台独立的设备上，从而提高数据的可靠性或读写性能。Etcd 是几个比较常见的服务发现应用之一，它支持 TTL 的支持和 HTTP Restful API，同时通过 Raft 一致性算法处理日志复制以保证强一致性。关于 Raft 算法，请参考 这篇文章，这里不多介绍。Etcd 本来就是 CoreOS 团队开发支持的，因此也是原生存在在 CoreOS 系统中。
Etcd 中提供了订阅通知机制，同时提供了一个线上服务 https://discovery.etcd.io/，这个服务可以用于发现集群中的机器。比如 Fleet 等等工具也是基于 Etcd 去发现网络中的节点服务器。在 CoreOS 机器部署之后，系统中一个叫做 cloud-init 的服务会根据之前的 user-data 文件去启动 Etcd。Etcd 会更新对应的自己的节点信息，并且获取其它的节点信息。
另外比较常见的服务发现还有 ZooKeeper（应用最广泛）、Consul 等等，如果有兴趣，可以自己在进行研究。
Etcdctl 使用 工具 etcdctl 是 etcd 的控制程序，我们可以通过执行命令查看所有键值：
core@core-01 ~ $ etcdctl ls / --recursive /coreos.com /coreos.com/network /coreos.com/network/config /coreos.com/network/subnets /coreos.com/network/subnets/10.1.64.0-24 /coreos.com/network/subnets/10.1.48.0-24 /coreos.com/network/subnets/10.1.10.0-24 /coreos.com/updateengine /coreos.com/updateengine/rebootlock /coreos.com/updateengine/rebootlock/semaphore 还可以通过类似 Redis 的 get 等命令获取具体存储内容：</description></item><item><title>CoreOS 折腾笔记（二）Fleet 进阶</title><link>https://www.4async.com/2016/05/2016-05-28-learning-coreos-part2/</link><pubDate>Sat, 28 May 2016 18:00:00 +0000</pubDate><guid>https://www.4async.com/2016/05/2016-05-28-learning-coreos-part2/</guid><description>如果要说什么样子的分布式集群对用户是最友好的，那无疑是对客户来说，像本地执行命令一样方便的执行集群命令肯定是最舒服的了。这个我们在上一节 集群部署 里面就提到了一个叫做 &amp;ldquo;fleetctl&amp;rdquo; 的命令，这个命令是做什么用的呢？
fleet 是什么 工具 fleet 是一个在集群层面上的 systemd 管理工具。它的配置文件语法基于 systemd 的语法，另外添加了一些自有的属性。如果你希望在集群中运行你的服务，那么使用 fleet 管理 systemd 单元是再有必要不过的了。
在比较新的系统 (CentOS 7+、Ubuntu 16+、Debian 8+) 中均采用了 systemd 作为启动项管理工具。如果你对 systemd 有疑问的话，请到其 官方网站 查看具体的介绍，这里不做赘述。
之前使用的 fleetctl 就是 fleet 的管理工具，默认是在集群中的某台机器上进行管理。当然，fleetctl 同样也可以通过远程进行管理，可以通过如下命令连接远程集群。
FLEETCTL_ENDPOINT=http://&amp;lt;IP:[PORT]&amp;gt; fleetctl list-units fleetctl 常见命令 比较常见的 fleetctl 命令有：
core@core-01 ~ $ fleetctl -h ... COMMANDS: cat 查看已经提交的单元文件内容 destroy 销毁集群中的一个或多个单元 fd-forward 将标准输入输出转向到一个 unix socket 中 journal 将集群中的某个 unit 的日志输出到当前 list-machines 查看集群中的已知机器 list-unit-files 查看集群中存在的单元 list-units 查看集群中的单元状态 load 将一个或多个单元加载到集群中，必要时会先执行 submit 功能 ssh 连接到集群中的某台机器 start 启动集群中一个或多个单元，必要时会先执行 submit 和 load 功能 status 输出集群中一个或多个单元的状态 stop 停止集群中一个或多个单元 submit 上传一个或多个单元到集群中，并不会加载执行 unload 卸载集群中的一个或多个单元 fleet 单元文件 以一个 Hello World 程序作为演示来讲解：</description></item><item><title>CoreOS 折腾笔记（一）集群部署</title><link>https://www.4async.com/2016/05/2016-05-28-learning-coreos-part1/</link><pubDate>Sat, 28 May 2016 17:00:00 +0000</pubDate><guid>https://www.4async.com/2016/05/2016-05-28-learning-coreos-part1/</guid><description>最近在技改完成之后打算进行大量的微服务化改造，而方便进行微服务化的步骤之一，就是将现有的系统移植进入 Docker 环境之中。在标准容器系统的选择上，我把目光放在了 CoreOS 上。实际上，我在 CoreOS 版本还是 2 开头的时候就有简单研究过，但是当时主要作为研究 Docker 的途径，现在则是作为集群化部署的基准系统。从本文开始的一系列折腾则是我在研究 CoreOS 集群化使用的一些纪录，而本文就是介绍一个本地实现容器化机群的步骤。
安装 Vagrant 略，因为太简单了。另外还需要 VirtualBox，不要忘记装。
配置 CoreOS-vagrant 执行以下命令：
git clone https://github.com/coreos/coreos-vagrant.git cd coreos-vagrant 下载 CoreOS 的 vagrant 配置。值得在进入正式配置之前一提的是，CoreOS 本身是没有默认密码或者安装密码机制的，也就是说，现有的所有认证登录需要通过 SSH 进行。如果是通过 vagrant 安装，会自动生成登录需要的 SSH 密钥，这个是需要额外注意的内容。
首先，将仓库中提供的两个模版配置文件复制成正式，接下来需要修改对应的文件：
cp config.rb.sample config.rb cp user-data.sample user-data 首先修改 config.rb 文件。这里重点是两个参数，一个是启动的实例数量，另外一个是升级的版本，我修改成了
$num_instances=4 $update_channel=&amp;#39;stable&amp;#39; 启动 4 个实例，升级选择的版本则是月度升级版。另外一个 user-data 暂时不作修改。
接下来执行：
vagrant up 在一堆输出之后，生成的 4 个实例就已经在运行了。也可以通过命令 vagrant status 查看运行状态。
➜ coreos-vagrant git:(master) vagrant status Current machine states: core-01 running (virtualbox) core-02 running (virtualbox) core-03 running (virtualbox) core-04 running (virtualbox) This environment represents multiple VMs.</description></item><item><title>Docker for Mac 尝鲜</title><link>https://www.4async.com/2016/04/2016-04-26-docker-for-mac-beta/</link><pubDate>Tue, 26 Apr 2016 18:00:00 +0000</pubDate><guid>https://www.4async.com/2016/04/2016-04-26-docker-for-mac-beta/</guid><description>之前作为 Docker beta 的第一批用户获得了 beta 的授权，但是因为邮件进了垃圾邮件，所以一直没有发现。今天给 Docker 发邮件申请 beta 测试才知道已经通过了，赶紧尝鲜起来。如果你没有权限，可以尝试到 Docker Beta 申请测试资格。
测试版本可能存在风险，请自行判断。
安装之前 Docker for Mac 需要一些前置要求，官方文档提供的数据如下：
2010 年之后的 Intel Mac 机型，支持 MMU(Memory Management Unit) 虚拟化、EPT(Extended Page Table) 等特性 OSX 10.10.3 以上系统 至少 4GB 内存 VirtualBox 4.x 与 Docker for Mac 冲突，因此如果你安装这个系列的 Virtualbox 需要卸载。 如果之前装过 Docker Toolbox 的话，需要一些额外的操作去与 Docker Toolbox 兼容。（我选择了直接卸载现有的 Docker Toolbox。XD ）
安装 Docker for Mac Docker for Mac 是一个 98.3M(Mac 显示为 103.1MB) 的 DMG 文件，下载下来之后双击文件，将鲸鱼拖拽到 Applications 文件夹中即可。</description></item><item><title>从 asyncio 简单实现看异步是如何工作的</title><link>https://www.4async.com/2016/02/2016-02-03-simple-implement-asyncio-to-understand-how-async-works/</link><pubDate>Wed, 03 Feb 2016 15:40:00 +0000</pubDate><guid>https://www.4async.com/2016/02/2016-02-03-simple-implement-asyncio-to-understand-how-async-works/</guid><description>从 asyncio 简单实现看异步是如何工作的
by ipfans
注：请使用 Python 3.5+ 版本运行以下代码。
先从例子看起 首先我们来看一个 socket 通讯的例子，这个例子我们可以在官方 socket 模块的文档中找到部分原型代码：
# echo.py from socket import * # 是的，这是一个不好的写法 def echo_server(address): sock = socket(AF_INET, SOCK_STREAM) sock.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1) sock.bind(address) sock.listen(5) while True: client, addr = sock.accept() print(&amp;#34;connect from&amp;#34;, addr) echo_handler(client) def echo_handler(client): while True: data = client.recv(10000) if not data: break client.send(str.encode(&amp;#34;Got: &amp;#34;) + data) print(&amp;#34;connection closed.&amp;#34;) if __name__ == &amp;#39;__main__&amp;#39;: echo_server((&amp;#39;&amp;#39;, 25000)) 但是同步模式会有一个问题，当进行通讯是阻塞的，当一个连接占用时就会阻碍其他连接的继续，这个时候应该怎么更快的运行呢？
回顾历史 在 asyncio 出现之前，我们都是怎么提高效率的呢？首先想到的方法就是多线程处理：</description></item></channel></rss>