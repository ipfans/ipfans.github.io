<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>asyncio on ipfans's Blog</title><link>https://www.4async.com/tags/asyncio/</link><description>Recent content in asyncio on ipfans's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 03 Feb 2016 15:40:00 +0000</lastBuildDate><atom:link href="https://www.4async.com/tags/asyncio/atom.xml" rel="self" type="application/rss+xml"/><item><title>从 asyncio 简单实现看异步是如何工作的</title><link>https://www.4async.com/2016/02/2016-02-03-simple-implement-asyncio-to-understand-how-async-works/</link><pubDate>Wed, 03 Feb 2016 15:40:00 +0000</pubDate><guid>https://www.4async.com/2016/02/2016-02-03-simple-implement-asyncio-to-understand-how-async-works/</guid><description>从 asyncio 简单实现看异步是如何工作的
by ipfans
注：请使用 Python 3.5+ 版本运行以下代码。
先从例子看起 首先我们来看一个 socket 通讯的例子，这个例子我们可以在官方 socket 模块的文档中找到部分原型代码：
# echo.py from socket import * # 是的，这是一个不好的写法 def echo_server(address): sock = socket(AF_INET, SOCK_STREAM) sock.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1) sock.bind(address) sock.listen(5) while True: client, addr = sock.accept() print(&amp;#34;connect from&amp;#34;, addr) echo_handler(client) def echo_handler(client): while True: data = client.recv(10000) if not data: break client.</description></item><item><title>Python 异步与性能迷思</title><link>https://www.4async.com/2015/11/2015-11-11-async-python/</link><pubDate>Wed, 11 Nov 2015 18:18:18 +0000</pubDate><guid>https://www.4async.com/2015/11/2015-11-11-async-python/</guid><description>今天在讨论 Python 的异步编程的时候提到的问题：到底为什么现在 Python 的异步数据库那么少呢？到底针对 Python 而言，什么是影响 Python 性能最大的门槛呢？
为了搞清楚这个问题，我对线上环境应用使用了性能探针系统。性能出人意料 (CPython 2.7.10)：
似乎真实来说，Python 本身的性能问题才是影响 Python 性能的真凶。
在此以前，我们谈这个之前，还是先复习一下什么是 GIL 吧。无论是 CPython(普通的 Python 2.7.x 和 Python 3.5.x) 还是 pypy，都是有一个名曰『Global Interpreter Lock』的东西限制了它的性能，用一张图可以生动的表现带 GIL 的 Python 在多核下的 CPU 压力：
GIL 限制了 Python 的 bytecode 只能在一个线程中运行，使用这种 GIL 避免多线程编程时隐含并发访问对象可能带来的潜在问题，但是也让 Python 在多核下性能表现感人。这种实现方式一直备受诟病，这也导致 Python 在某些高并发场景时会出现较严重的性能下滑问题。
在 Python 性能提升上，比较常见的性能提升的方式，是将多线程转化为多进程方式，以充分利用 CPU 多核心。但是这样带来直接的问题是进程间通讯会严重影响整体程序的吞吐量。一个简单的 CPU 密集 Python socket 的通讯程序，非 Block 状态下，吞吐量能有大概 10 倍以上的差距。(参考 Python Concurrency From the Ground Up )
不过相对来说，这样虽然影响了最大吞吐量，但是在利用多核效率上提升明显，即便是 CPU 密集的情况，也能保证程序的整体吞吐量不会出现线程模式的成百上千倍的性能差距。</description></item><item><title>PEP 0492 Coroutines with async and await syntax 中文翻译</title><link>https://www.4async.com/2015/10/2015-10-31-coroutines-with-async-and-await-syntax-chinese/</link><pubDate>Sat, 31 Oct 2015 12:48:15 +0000</pubDate><guid>https://www.4async.com/2015/10/2015-10-31-coroutines-with-async-and-await-syntax-chinese/</guid><description>原文地址: PEP-0492
PEP 492 标题 协程与 async/await 语法 作者 Yury Selivanov &amp;lt;yury at magic.io&amp;gt; 翻译 ipfans &amp;lt;ipfanscn at gmail.com&amp;gt; 状态 最终稿 Python 版本 3.5 翻译最后更新 2015-11-03 目录
摘要 API 设计和实现的备注 基本原理和目标
语法规范
新协程声明语法 types.coroutine() Await 表达式 新的操作符优先级列表 await 表达式示例 异步上下文管理与 async with 新语法 例子 异步迭代器与 async for 新语法 例子 1 例子 2 为什么使用 StopAsyncIteration 协程对象 与生成器的不同之处 协程对象方法 调试特性 新的标准库函数 新的抽象基类 专用术语表</description></item><item><title>从零实现一个 Redis 客户端（二）</title><link>https://www.4async.com/2015/10/2015-10-30-write-aio-python-redis-client-as-dummy-2/</link><pubDate>Fri, 30 Oct 2015 23:11:15 +0000</pubDate><guid>https://www.4async.com/2015/10/2015-10-30-write-aio-python-redis-client-as-dummy-2/</guid><description>从 Call 到命令端 在第一个文章中，我们介绍了实现一个 Call 的客户端基本模型，但只是 Call 怎么能满足需求呢？比如在 redis-py 中，一个完整的客户端应该是这样的：
client = redis.StrictRedis() client.setex(&amp;#34;key&amp;#34;, 10, &amp;#34;value&amp;#34;) 接下来作为一个程序的客户端，需要去做的就是封装出一个 Redis Client。比如 setex 方法：
def setex(self, key, seconds, value): &amp;#34;&amp;#34;&amp;#34;Set the value and expiration of a key. :raises TypeError: if seconds is neither int &amp;#34;&amp;#34;&amp;#34;if not isinstance(seconds, int): raise TypeError(&amp;#34;milliseconds argument must be int&amp;#34;) fut = self._conn.execute(b&amp;#39;SETEX&amp;#39;, key, seconds, value) return wait_ok(fut) 剩下的就是一个个方法逐个完善。
什么是连接池 我们会看到，无论那个数据库客户端，总是会有连接池机制。那么连接池是什么呢？我们为什么需要连接池呢？
首先，我们都知道，对连接而言，创建是必要重型的操作。比如说，TCP 连接，接下来之后是登录认证等等过程，最后才会执行命令。这也就是我们通常计算库性能时，很多时候会把建立连接的时候去掉。但是这就出现了一个问题，当一个连接被占用时，其他的操作仍旧是不能够完成操作了，只能等待前一个操作完成。但是假如我们一次性创建一堆连接呢？从一堆连接中找到空闲的连接，使用完成后释放成空闲的状态，这就是线程池的本质。因为减少了每次创建连接的过程，所以对性能提升也非常有帮助。
从单连接到连接池 首先，还是创建一个 RedisPool 类，用于管理 Redis 的连接池。</description></item><item><title>零基础编写 Python Redis Client（一）</title><link>https://www.4async.com/2015/10/2015-10-10-write-aio-python-redis-client-as-dummy-1/</link><pubDate>Sat, 10 Oct 2015 18:11:15 +0000</pubDate><guid>https://www.4async.com/2015/10/2015-10-10-write-aio-python-redis-client-as-dummy-1/</guid><description>什么是 AIO AIO 是 Asynchronous Input/Output 的简写，也就是异步 IO。不过在谈什么是 AIO 之前，我们可能要先介绍一下 BIO。那么什么是 BIO 呢？简单的说，BIO 是 Blocking Input/Output，也就是阻塞 IO，他实现的通常是在线程池中找出一个线程处理 IO，在 IO 过程中，其他线程都需要等待 IO 完成后才可以从中选取一个线程占用 IO。这样最大的问题是，当线程数量较多，并且需要大量的 IO 操作时，就会造成一个大量的阻塞，因为实际上每次只有一个线程在处理 IO。
那么如何解决这个时候的问题呢？这时候就提出了 AIO 的概念。通常在 IO 处理过程中也会伴有一些其他的处理操作，假如把所有的操作都浪费在了等待 IO 释放上，线程池中的线程利用率也太低了，因此我们需要一种方式，在申请 IO 处理之后，就去继续做其他的事情，等 IO 操作完成了，然后通知我们已经 OK，我们可以继续处理了。这也就是我们常说的 AIO 的原型。
AIO 的情况也说明了它适用的场景：长连接场景，或者重度的 IO 操作等等的情况。
如果找软件来做案例，我们可以找一个可能大家熟知的：NGINX。正如我们所知，NGINX 采用了 异步、事件驱动的方法来处理连接。这种处理方式无需（像使用传统架构的服务器一样）为每个请求创建额外的专用进程或者线程，而是在一个工作进程中处理多个连接和请求。为此，NGINX 工作在非阻塞的 socket 模式下，并使用了 epoll 和 kqueue 这样有效的方法。
这部分的内容，在 NGINX 引入线程池 性能提升 9 倍 中进行了详细的介绍，包含了 NGINX 的异步应用经验，同时介绍了 NGINX 中引入了阻塞的线程池用于解决某些特定场景问题下的效率。
如何实现 Python 的异步 IO 这篇文章会以最新的 Python 3.</description></item><item><title>Python async/await 入门</title><link>https://www.4async.com/2015/08/2015-08-14-introduction-to-async-and-await/</link><pubDate>Fri, 14 Aug 2015 18:11:15 +0000</pubDate><guid>https://www.4async.com/2015/08/2015-08-14-introduction-to-async-and-await/</guid><description>在新版 Python3.5 中，引入了两个新关键字 async 和 await，用于解决在 Python 异步编程中无法有效 区分 yield 生成器与异步的关系的问题。
异步是一个什么东西 异步的作用在于，对于 Python 这种拥有 GIL 的语言，某个线程在处理单个耗时较长的任务时（如 I/O 读取，RESTful API 调用）等操作时，不能有效的释放 CPU 资源，导致其他线程的等待时间随之增加。 异步的作用是，在等待这种花费大量时间的操作数，允许释放 CPU 资源执行其他的线程任务，从而提 高程序的执行效率。
3.4 之前如何实现异步 在 3.5 版本以前的程序中，Python 程序通常是使用 yield 作为一个判断是否进入异步操作的关键词。 比如在 3.4.x 版本中，我们可以用这样的一个例子来看一下 (或者你也可以用一个 Tornado 的例子，这 样你的程序就也可以运行在 2.7.x 版本的 Python 中了)：
import time import asyncio @asyncio.coroutine def slow_operation(n): yield from asyncio.sleep(1) print(&amp;#34;Slow operation {}complete&amp;#34;.format(n)) @asyncio.coroutine def main(): start = time.</description></item></channel></rss>