<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='译者注：最近 Python 3.12 引入了子解释器概念，非常火热，更好的消息是已经在FastAPI应用成功了，虽然是很简单的那种。因此顺腾摸瓜，找到了作者的博客，翻译分享给大家。
Python 3.12 引入了一个新的 API 用于“子解释器”（sub interpreters），这是 Python 的一种不同的并行执行模型，提供了真正并行处理和多进程处理之间的良好折中，且具有更快的启动时间。在这篇文章中，我将解释什么是子解释器，为什么它对 Python 中的并行代码执行很重要，以及它与其他方法的比较。
什么是子解释器？ Python 的系统架构大致由三部分组成：
一个包含一个或多个解释器的 Python 进程 一个包含锁（GIL）和一个或多个 Python 线程的解释器 一个包含当前执行代码信息的线程。 要了解更多关于这方面的信息，你可以阅读我的书《CPython 内部实现》中的“并行性和并发性”章节。
自 Python 1.5 以来，就有一个 C-API 可以支持多个解释器，但这个功能由于 GIL 的限制而受到严重限制，没有真正实现真正的并行性。因此，运行并行代码最常用的技术（不使用第三方库）是使用 multiprocessing 模块。
2017 年，CPython 核心开发人员提出改变解释器结构的提议，使它们更好地与拥有它们的 Python 进程隔离，并能够并行操作。实现这一目标的工作相当巨大（6 年后仍未完成），并分为两个 PEP。PEP684 将 GIL 在各个解释器独立开，PEP554 提供了一个创建解释器和在它们之间共享数据的 API。
GIL 是“全局解释器锁”，是 Python 进程中的一个锁，意味着在任何时间点 Python 进程中只能执行一条指令，即使它有多个线程。这实际上意味着，即使你在拥有 4 核 CPU 的电脑上同时启动 4 个 Python 线程，也只有一个线程会在任何时候运行。
你可以通过创建一个 numpy 数组或整数，并粗略计算每个值与 50 的距离来进行一个简单的测试：
import numpy # Create a random array of 100,000 integers between 0 and 100 a = numpy.'><title>使用子解释器运行Python并行应用</title>
<link rel=canonical href=https://www.4async.com/2023/11/python-312-sub-interpreters/><link rel=stylesheet href=../../../scss/style.min.abbd69b2908fdfcd5179898beaafd374514a86538d81639ddd2c58c06ae54e40.css><meta property='og:title' content='使用子解释器运行Python并行应用'><meta property='og:description' content='译者注：最近 Python 3.12 引入了子解释器概念，非常火热，更好的消息是已经在FastAPI应用成功了，虽然是很简单的那种。因此顺腾摸瓜，找到了作者的博客，翻译分享给大家。
Python 3.12 引入了一个新的 API 用于“子解释器”（sub interpreters），这是 Python 的一种不同的并行执行模型，提供了真正并行处理和多进程处理之间的良好折中，且具有更快的启动时间。在这篇文章中，我将解释什么是子解释器，为什么它对 Python 中的并行代码执行很重要，以及它与其他方法的比较。
什么是子解释器？ Python 的系统架构大致由三部分组成：
一个包含一个或多个解释器的 Python 进程 一个包含锁（GIL）和一个或多个 Python 线程的解释器 一个包含当前执行代码信息的线程。 要了解更多关于这方面的信息，你可以阅读我的书《CPython 内部实现》中的“并行性和并发性”章节。
自 Python 1.5 以来，就有一个 C-API 可以支持多个解释器，但这个功能由于 GIL 的限制而受到严重限制，没有真正实现真正的并行性。因此，运行并行代码最常用的技术（不使用第三方库）是使用 multiprocessing 模块。
2017 年，CPython 核心开发人员提出改变解释器结构的提议，使它们更好地与拥有它们的 Python 进程隔离，并能够并行操作。实现这一目标的工作相当巨大（6 年后仍未完成），并分为两个 PEP。PEP684 将 GIL 在各个解释器独立开，PEP554 提供了一个创建解释器和在它们之间共享数据的 API。
GIL 是“全局解释器锁”，是 Python 进程中的一个锁，意味着在任何时间点 Python 进程中只能执行一条指令，即使它有多个线程。这实际上意味着，即使你在拥有 4 核 CPU 的电脑上同时启动 4 个 Python 线程，也只有一个线程会在任何时候运行。
你可以通过创建一个 numpy 数组或整数，并粗略计算每个值与 50 的距离来进行一个简单的测试：
import numpy # Create a random array of 100,000 integers between 0 and 100 a = numpy.'><meta property='og:url' content='https://www.4async.com/2023/11/python-312-sub-interpreters/'><meta property='og:site_name' content="ipfans's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Software Architecture'><meta property='article:tag' content='Python'><meta property='article:published_time' content='2023-11-23T09:39:00+00:00'><meta property='article:modified_time' content='2023-11-23T09:39:00+00:00'><meta property='og:image' content='https://www.4async.com/2023/11/python-312-sub-interpreters/cover.webp'><meta name=twitter:site content="@janxin"><meta name=twitter:creator content="@janxin"><meta name=twitter:title content="使用子解释器运行Python并行应用"><meta name=twitter:description content="译者注：最近 Python 3.12 引入了子解释器概念，非常火热，更好的消息是已经在FastAPI应用成功了，虽然是很简单的那种。因此顺腾摸瓜，找到了作者的博客，翻译分享给大家。
Python 3.12 引入了一个新的 API 用于“子解释器”（sub interpreters），这是 Python 的一种不同的并行执行模型，提供了真正并行处理和多进程处理之间的良好折中，且具有更快的启动时间。在这篇文章中，我将解释什么是子解释器，为什么它对 Python 中的并行代码执行很重要，以及它与其他方法的比较。
什么是子解释器？ Python 的系统架构大致由三部分组成：
一个包含一个或多个解释器的 Python 进程 一个包含锁（GIL）和一个或多个 Python 线程的解释器 一个包含当前执行代码信息的线程。 要了解更多关于这方面的信息，你可以阅读我的书《CPython 内部实现》中的“并行性和并发性”章节。
自 Python 1.5 以来，就有一个 C-API 可以支持多个解释器，但这个功能由于 GIL 的限制而受到严重限制，没有真正实现真正的并行性。因此，运行并行代码最常用的技术（不使用第三方库）是使用 multiprocessing 模块。
2017 年，CPython 核心开发人员提出改变解释器结构的提议，使它们更好地与拥有它们的 Python 进程隔离，并能够并行操作。实现这一目标的工作相当巨大（6 年后仍未完成），并分为两个 PEP。PEP684 将 GIL 在各个解释器独立开，PEP554 提供了一个创建解释器和在它们之间共享数据的 API。
GIL 是“全局解释器锁”，是 Python 进程中的一个锁，意味着在任何时间点 Python 进程中只能执行一条指令，即使它有多个线程。这实际上意味着，即使你在拥有 4 核 CPU 的电脑上同时启动 4 个 Python 线程，也只有一个线程会在任何时候运行。
你可以通过创建一个 numpy 数组或整数，并粗略计算每个值与 50 的距离来进行一个简单的测试：
import numpy # Create a random array of 100,000 integers between 0 and 100 a = numpy."><meta name=twitter:card content="summary"><meta name=twitter:image content='https://www.4async.com/2023/11/python-312-sub-interpreters/cover.webp'><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-33841232-2","auto"),ga("send","pageview"))</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=../../../><img src=../../../img/avatar_huae056372e08c63f80862e9295e80f934_12087_300x0_resize_q75_box.jpeg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=../../../>ipfans's Blog</a></h1><h2 class=site-description></h2></div></header><ol class=menu id=main-menu><li><a href=../../../><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=../../../about><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=../../../archives><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=../../../atom.xml><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg>
<span>Feed</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#什么是子解释器>什么是子解释器？</a></li><li><a href=#关于移除-gil-的工作怎么样了这不会让之前的工作变得无关紧要吗>关于移除 GIL 的工作怎么样了？这不会让之前的工作变得无关紧要吗？</a></li><li><a href=#线程多进程和子解释器之间有什么区别>线程、多进程和子解释器之间有什么区别？</a></li><li><a href=#子解释器在实际性能方面如何比较>子解释器在实际性能方面如何比较？</a></li><li><a href=#很好那么所有并行工作负载使用子解释器都会更快吗>很好！那么所有并行工作负载使用子解释器都会更快吗？</a></li><li><a href=#在解释器和进程已经启动并运行后对性能有影响吗>在解释器和进程已经启动并运行后，对性能有影响吗？</a><ul><li><a href=#工作进程间通信>工作进程间通信</a></li><li><a href=#工作进程状态管理>工作进程状态管理</a></li></ul></li><li><a href=#如何使用子解释器>如何使用子解释器？</a></li><li><a href=#web-应用中的并行工作机制>Web 应用中的并行工作机制</a></li><li><a href=#应用子解释器到-web-应用中>应用子解释器到 Web 应用中</a></li><li><a href=#发现>发现</a></li></ul></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=../../../2023/11/python-312-sub-interpreters/><img src=../../../2023/11/python-312-sub-interpreters/cover_hub19c0c7aa8bd91457fe7a878cea732e1_594356_800x0_resize_q75_h2_box_2.webp srcset="../../../2023/11/python-312-sub-interpreters/cover_hub19c0c7aa8bd91457fe7a878cea732e1_594356_800x0_resize_q75_h2_box_2.webp 800w, ../../../2023/11/python-312-sub-interpreters/cover_hub19c0c7aa8bd91457fe7a878cea732e1_594356_1600x0_resize_q75_h2_box_2.webp 1600w" width=800 height=457 loading=lazy alt="Featured image of post 使用子解释器运行Python并行应用"></a></div><div class=article-details><header class=article-category><a href=../../../categories/software-architecture/>Software Architecture</a></header><div class=article-title-wrapper><h2 class=article-title><a href=../../../2023/11/python-312-sub-interpreters/>使用子解释器运行Python并行应用</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Nov 23, 2023</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 4 分钟</time></div></footer></div></header><section class=article-content><blockquote><p>译者注：最近 Python 3.12 引入了子解释器概念，非常火热，更好的消息是已经<a class=link href=https://twitter.com/anthonypjshaw/status/1723916190202945761 target=_blank rel=noopener>在FastAPI应用成功</a>了，虽然是很简单的那种。因此顺腾摸瓜，找到了作者的<a class=link href=https://tonybaloney.github.io/posts/sub-interpreter-web-workers.html target=_blank rel=noopener>博客</a>，翻译分享给大家。</p></blockquote><p>Python 3.12 引入了一个新的 API 用于“子解释器”（sub interpreters），这是 Python 的一种不同的并行执行模型，提供了真正并行处理和多进程处理之间的良好折中，且具有更快的启动时间。在这篇文章中，我将解释什么是子解释器，为什么它对 Python 中的并行代码执行很重要，以及它与其他方法的比较。</p><h2 id=什么是子解释器>什么是子解释器？</h2><p>Python 的系统架构大致由三部分组成：</p><ul><li>一个包含一个或多个解释器的 Python 进程</li><li>一个包含锁（GIL）和一个或多个 Python 线程的解释器</li><li>一个包含当前执行代码信息的线程。</li></ul><p><img src=../../../2023/11/python-312-sub-interpreters/interpreter-states-1.png width=2111 height=1898 srcset="../../../2023/11/python-312-sub-interpreters/interpreter-states-1_hu0b19f16c8914c60850e2d92dce0c877e_192375_480x0_resize_box_3.png 480w, ../../../2023/11/python-312-sub-interpreters/interpreter-states-1_hu0b19f16c8914c60850e2d92dce0c877e_192375_1024x0_resize_box_3.png 1024w" loading=lazy alt="interpreter states" class=gallery-image data-flex-grow=111 data-flex-basis=266px></p><p>要了解更多关于这方面的信息，你可以阅读我的书<a class=link href=https://tonybaloney.github.io/#books target=_blank rel=noopener>《CPython 内部实现》</a>中的“并行性和并发性”章节。</p><p>自 Python 1.5 以来，就有一个 C-API 可以支持多个解释器，但这个功能由于 GIL 的限制而受到严重限制，没有真正实现真正的并行性。因此，运行并行代码最常用的技术（不使用第三方库）是使用 <a class=link href=https://docs.python.org/3/library/multiprocessing.html target=_blank rel=noopener>multiprocessing 模块</a>。</p><p>2017 年，CPython 核心开发人员提出改变解释器结构的提议，使它们更好地与拥有它们的 Python 进程隔离，并能够并行操作。实现这一目标的工作相当巨大（6 年后仍未完成），并分为两个 PEP。PEP684 将 GIL 在各个解释器独立开，PEP554 提供了一个创建解释器和在它们之间共享数据的 API。</p><p>GIL 是“全局解释器锁”，是 Python 进程中的一个锁，意味着在任何时间点 Python 进程中只能执行一条指令，即使它有多个线程。这实际上意味着，即使你在拥有 4 核 CPU 的电脑上同时启动 4 个 Python 线程，也只有一个线程会在任何时候运行。</p><p><img src=../../../2023/11/python-312-sub-interpreters/hard-working-snake.jpeg width=1024 height=1024 srcset="../../../2023/11/python-312-sub-interpreters/hard-working-snake_huf677ab5284dc3059c291ae31652dfe1d_105085_480x0_resize_q75_box.jpeg 480w, ../../../2023/11/python-312-sub-interpreters/hard-working-snake_huf677ab5284dc3059c291ae31652dfe1d_105085_1024x0_resize_q75_box.jpeg 1024w" loading=lazy class=gallery-image data-flex-grow=100 data-flex-basis=240px></p><p>你可以通过创建一个 numpy 数组或整数，并粗略计算每个值与 50 的距离来进行一个简单的测试：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy
</span></span><span style=display:flex><span><span style=color:#75715e># Create a random array of 100,000 integers between 0 and 100</span>
</span></span><span style=display:flex><span>a <span style=color:#f92672>=</span> numpy<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>100_000</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> a:
</span></span><span style=display:flex><span>  abs(x <span style=color:#f92672>-</span> <span style=color:#ae81ff>50</span>)
</span></span></code></pre></div><p>理论上，你会期望（至少在像 C 语言这样的语言中），通过将工作分割成块并将工作分配给线程，执行时间会更快：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy<span style=color:#f92672>,</span> threading
</span></span><span style=display:flex><span>a <span style=color:#f92672>=</span> numpy<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>100_000</span>)
</span></span><span style=display:flex><span>threads <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#75715e># Split array into blocks of 100 and start a thread for each</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ar <span style=color:#f92672>in</span> numpy<span style=color:#f92672>.</span>split(a, <span style=color:#ae81ff>100</span>):
</span></span><span style=display:flex><span>    t <span style=color:#f92672>=</span> threading<span style=color:#f92672>.</span>Thread(target<span style=color:#f92672>=</span>simple_abs_range, args<span style=color:#f92672>=</span>(ar,))
</span></span><span style=display:flex><span>    t<span style=color:#f92672>.</span>start()
</span></span><span style=display:flex><span>    threads<span style=color:#f92672>.</span>append(t)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> t <span style=color:#f92672>in</span> threads:
</span></span><span style=display:flex><span>    t<span style=color:#f92672>.</span>join()
</span></span></code></pre></div><p>实际上，在第二个例子中，执行速度是第一个的两倍慢。这是因为所有这些线程都绑定到同一个 GIL，且任何时候只有一个线程会执行。额外的时间全部花在了启动线程上，却几乎没完成什么实质工作。</p><p>尽管名为 GIL（全局解释器锁），但它实际上从来不是解释器状态中的真正锁。PEP684 通过停止在解释器之间共享 GIL 来改变这一点，使得 Python 进程中的每个解释器都有自己的 GIL，因此可以并行运行。per-interpreter GIL 工作耗时多年的主要原因是 CPython 在内部依赖 GIL 作为线程安全的来源。这表现为许多 C 扩展具有全局共享状态。如果在同一 Python 进程中引入并行性，并且两个解释器尝试写入同一内存空间，就会发生糟糕的事情。</p><p>在 Python 3.12 中，以及 Python 3.13 中正在进行的工作中，Python 标准库中用 C 语言编写的扩展正在被测试，并且任何全局共享状态都正在被移动到一个新的 API 中，该 API 将该状态放在模块内或解释器状态内。即使这项工作完成后，第三方 C 扩展可能也需要在子解释器中进行测试（我维护的一个用 C++编写的库就<a class=link href=https://github.com/microsoft/picologging/pull/167 target=_blank rel=noopener>需要修改</a>）。</p><h2 id=关于移除-gil-的工作怎么样了这不会让之前的工作变得无关紧要吗>关于移除 GIL 的工作怎么样了？这不会让之前的工作变得无关紧要吗？</h2><p><a class=link href=https://peps.python.org/pep-0703/ target=_blank rel=noopener>最近批准的提案 PEP703</a>，旨在使 CPython 中的 GIL 成为可选项，与 per-interpreter GIL 的工作相辅相成。这两个提案都有以下先决条件：</p><ul><li>Immortal Objects</li><li>更新 C 扩展以避免使用共享的全局状态</li></ul><p>另一个重要点是，尽管 PEP703 已被接受，但它是作为一个可选标志进行的，如果证明过于复杂或问题重重，则未来可能会撤销这些更改。另一方面，per-interpreter GIL 的工作基本上已经完成，并且不需要在 CPython 中使用另一个编译时标志。</p><p>关于 PEP703，我将来会写更多内容。在这篇文章的后面，我会分享一些代码，我将尝试将这两种方法结合起来。</p><h2 id=线程多进程和子解释器之间有什么区别>线程、多进程和子解释器之间有什么区别？</h2><p>Python 标准库提供了一些并发编程的选项，这取决于一些因素：</p><ul><li>您正在完成的任务是否是 IO 绑定的（例如，从网络读取，写入磁盘）</li><li>任务是否需要大量的 CPU 计算</li><li>任务是否可以分解为小块，或者它们是大块的工作？</li></ul><p>这里是不同的模型：</p><ul><li>线程创建快速，你可以在它们之间共享任何 Python 对象，且开销小。缺点是 Python 线程绑定到进程的 GIL，所以如果工作负载是 CPU 密集型的，你不会看到任何性能提升。线程非常适合后台轮询任务，比如一个等待并监听队列上消息的函数。</li><li>协程创建极快，你可以在它们之间共享任何 Python 对象，且开销极小。协程是基于 IO 活动的理想选择，尤其是那些支持 async/await 的底层 API。</li><li>多进程是 Python 的一个包装器，用于创建 Python 进程并将它们链接在一起。这些进程启动缓慢，所以你给它们的工作量需要足够大，才能看到并行化工作的好处。然而，它们是真正的并行，因为每个进程都有自己的 GIL。</li><li>子解释器具有多进程的并行性，但启动时间更快。</li></ul><p>我在 2023 年 PyCon APAC 上关于这个话题做了一个<a class=link href="https://youtu.be/mqOQtC9Dt84?t=6850" target=_blank rel=noopener>演讲</a>，你可以查看那个演讲以获得详细的口头解释。</p><p>或者，用表格来表示：</p><p>:&ndash;|:&ndash;|:&ndash;|:&ndash;
Model|Execution|Start-up time|Data Exchange
threads|Parallel*|small|Any
coroutines|Concurrent|smallest|Any
Async functions|Concurrent|smallest|Any
Greenlets|Concurrent|smallest|Any
multiprocessing|ParalleL|large|Serialization
Sub Interpreters|Parallel|medium|Serialization or Shared Memory</p><p><em>* 正如我们探讨的，线程仅在 IO 绑定任务中是并行的。</em></p><h2 id=子解释器在实际性能方面如何比较>子解释器在实际性能方面如何比较？</h2><p>在一个简单的基准测试中，我测量了创建以下内容的时间：</p><ul><li>100 个线程</li><li>100 个子解释器</li><li>使用多进程的 100 个进程</li></ul><p>以下是结果：</p><p><img src=../../../2023/11/python-312-sub-interpreters/results_bare_execution.png width=1229 height=538 srcset="../../../2023/11/python-312-sub-interpreters/results_bare_execution_hu6c120b6a28964f5d984aba99eea27b21_28201_480x0_resize_box_3.png 480w, ../../../2023/11/python-312-sub-interpreters/results_bare_execution_hu6c120b6a28964f5d984aba99eea27b21_28201_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=228 data-flex-basis=548px></p><p>这个基准测试显示，线程启动的速度大约比子解释器快 100 倍，而子解释器的启动速度则比多进程快大约 10 倍。我希望这个图表能清楚地表明，与多进程相比，解释器与线程有多么接近。</p><p>这个基准测试也没有衡量数据共享的性能（在子解释器中比多进程快得多）以及内存开销（同样显著减少）。</p><p>不并行运行任何东西并不是一个非常有用的基准测试，除了用于测量最小启动时间之外。接下来，我对一个 CPU 密集型的工作负载进行了基准测试，计算 Pi 到 2000 个小数位。</p><p><img src=../../../2023/11/python-312-sub-interpreters/results_pi_execution.png width=1233 height=538 srcset="../../../2023/11/python-312-sub-interpreters/results_pi_execution_hu61fccd536ed737862ba9f7463a8ca3b1_28745_480x0_resize_box_3.png 480w, ../../../2023/11/python-312-sub-interpreters/results_pi_execution_hu61fccd536ed737862ba9f7463a8ca3b1_28745_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=229 data-flex-basis=550px></p><h2 id=很好那么所有并行工作负载使用子解释器都会更快吗>很好！那么所有并行工作负载使用子解释器都会更快吗？</h2><p>遗憾的是，并非如此。回到第一个基准测试，子解释器的启动速度仍然比线程慢 100 倍。所以，如果任务真的很小，例如计算 Pi 到 200 位数字，那么并行性的好处会超过启动开销，线程仍然更快：</p><p><img src=../../../2023/11/python-312-sub-interpreters/results_pi_execution_200.png width=1242 height=538 srcset="../../../2023/11/python-312-sub-interpreters/results_pi_execution_200_hub7d81711a41f30b64da8aa0981152316_28783_480x0_resize_box_3.png 480w, ../../../2023/11/python-312-sub-interpreters/results_pi_execution_200_hub7d81711a41f30b64da8aa0981152316_28783_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=230 data-flex-basis=554px></p><p>为了直观地解释存在一个“临界点”，在该点上并行性变得更快的概念，这张图展示了工作量大小和执行时间增长速率。临界时间并不是一个固定值，因为它取决于 CPU、后台任务和许多其他变量。</p><p><img src=../../../2023/11/python-312-sub-interpreters/graph-sub-interpreters.png width=4221 height=1902 srcset="../../../2023/11/python-312-sub-interpreters/graph-sub-interpreters_hu8f4c8aa2db8d063aad8546cd5fa9b919_438368_480x0_resize_box_3.png 480w, ../../../2023/11/python-312-sub-interpreters/graph-sub-interpreters_hu8f4c8aa2db8d063aad8546cd5fa9b919_438368_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=221 data-flex-basis=532px></p><p>另一个重要的观点是，多进程通常被用于一种模型，其中进程长时间运行并处理大量任务，而不是为了单个工作负载而被创建和销毁。一个很好的例子是 Gunicorn，这是一个流行的 Python 网络服务器。Gunicorn 将使用多进程技术生成“工作进程”，这些工作进程将存活于主进程的整个生命周期。当网络工作进程可能运行数周、数月甚至数年时，启动进程或子解释器的时间（分别是 89 毫秒或 1 秒）就变得无关紧要。对于小任务（如处理单个网络请求）使用这些并行工作进程的理想方式是保持它们运行，并使用主进程来协调和分配工作负载：</p><p><img src=../../../2023/11/python-312-sub-interpreters/interpreter-spooling.png width=3964 height=1911 srcset="../../../2023/11/python-312-sub-interpreters/interpreter-spooling_hua3bb7f9ef0b56d785fcd9afee3dc21b7_332845_480x0_resize_box_3.png 480w, ../../../2023/11/python-312-sub-interpreters/interpreter-spooling_hua3bb7f9ef0b56d785fcd9afee3dc21b7_332845_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=207 data-flex-basis=497px></p><p>当您使用多进程或子解释器时，每个进程或解释器都有自己的导入状态。这与线程和协程截然不同。当您等待一个异步函数时，您不需要担心该协程是否已经导入了所需的模块。线程也是如此。例如，您可以在模块中导入某些内容，并从线程函数内部引用它：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> threading
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> super.duper.module <span style=color:#f92672>import</span> cool_function
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>worker</span>(info):
</span></span><span style=display:flex><span>    cool_function() <span style=color:#75715e># This already exists in the interpreter state</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>info <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;a&#39;</span>: <span style=color:#ae81ff>1</span>}
</span></span><span style=display:flex><span>thread <span style=color:#f92672>=</span> Thread(target<span style=color:#f92672>=</span>worker, args<span style=color:#f92672>=</span>(info, ))
</span></span></code></pre></div><p>启动解释器所需时间的一半用于执行“site import”。这是一个名为 <code>site.py</code> 的特殊模块，位于 Python 安装目录中。解释器拥有自己的缓存和内置模块，它们实际上是迷你的 Python 进程。启动线程或协程之所以如此快速，是因为它们不需要执行这些初始化工作（它们与拥有它们的解释器共享状态），但它们受限于锁并且不是并行的。</p><h2 id=在解释器和进程已经启动并运行后对性能有影响吗>在解释器和进程已经启动并运行后，对性能有影响吗？</h2><p>当使用像多进程或子解释器这样的并行执行模型时，下一个考虑点是如何共享数据。一旦克服了启动的障碍，这很快就成为最重要的问题。你需要回答两个问题：</p><ol><li>我们如何在工作进程间通信？</li><li>我们如何管理工作进程的状态？</li></ol><p>我们分别来讨论这些问题。</p><h3 id=工作进程间通信>工作进程间通信</h3><p>无论是使用子解释器还是多进程，你都不能简单地向工作进程发送现有的 Python 对象。</p><p>多进程默认使用 <code>pickle</code>。当你启动一个进程或使用<a class=link href=https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor target=_blank rel=noopener>进程池</a>时，你可以使用管道、队列和共享内存作为向工作进程和主进程发送/接收数据的机制。这些机制都围绕着 pickle。Pickle 是 Python 的内置序列化库，可以将大多数 Python 对象转换为字节字符串，然后再转换回 Python 对象。</p><p>Pickle 非常灵活。你可以序列化许多不同类型的 Python 对象（但不是全部），Python 对象甚至可以定义它们<a class=link href=https://docs.python.org/3/library/pickle.html#pickling-class-instances target=_blank rel=noopener>如何被序列化的方法</a>。它还处理嵌套对象和属性。然而，随着这种灵活性带来了性能损失。Pickle 是缓慢的。因此，如果你有一个依赖于持续的工作进程间复杂 pickled 数据通信的工作模型，你可能会看到瓶颈。</p><p>子解释器可以接受 pickled 数据。它们还有第二种机制叫做共享数据。共享数据是一个高速共享内存空间，解释器可以写入并与其他解释器共享数据。它只支持不可变类型，这些是：</p><ul><li>字符串</li><li>字节字符串</li><li>整数和浮点数</li><li>布尔值和 None</li><li>元组（及元组的元组）</li></ul><p>我上周<a class=link href=https://github.com/python/cpython/pull/111628 target=_blank rel=noopener>实现了元组共享机制</a>，以便我们有一些序列类型的选项。</p><p>要与解释器共享数据，你可以将其设置为初始化数据，或者通过一个通道发送。</p><h3 id=工作进程状态管理>工作进程状态管理</h3><p>对于子解释器来说，这是一个正在进行的工作。如果子解释器崩溃，它不会杀死主解释器。异常可以被提升到主解释器并优雅地处理。这方面的细节仍在研究中。</p><h2 id=如何使用子解释器>如何使用子解释器？</h2><p>在 Python 3.12 中，子解释器 API 是实验性的，我要提到的一些东西只在一周前实现，还没有发布，所以你会在未来的 3.13 版本中看到它们。如果你想编译 CPython 的主分支，你可以自己操作。</p><p><a class=link href=https://peps.python.org/pep-0554/ target=_blank rel=noopener>PEP554</a> 提出的 interpreters 模块尚未完成。它的一个版本是一个秘密的、隐藏的模块，叫做<code>_xxsubinterpreters</code>。在我所有的代码中，我将导入重命名为<code>interpreters</code>，因为这将是它在将来的名称。</p><p>你可以使用``.run()`函数创建、运行和停止子解释器，该函数接受一个字符串或一个简单的函数。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> _xxsubinterpreters <span style=color:#66d9ef>as</span> interpreters
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>run(<span style=color:#e6db74>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>print(&#34;Hello World&#34;)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>&#39;&#39;&#39;</span>)
</span></span></code></pre></div><p>启动子解释器是一个阻塞操作，因此大多数时候你需要在一个线程内启动它。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> threading <span style=color:#f92672>import</span> Thread
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> _xxsubinterpreters <span style=color:#66d9ef>as</span> interpreters
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>t <span style=color:#f92672>=</span> Thread(target<span style=color:#f92672>=</span>interpreters<span style=color:#f92672>.</span>run, args<span style=color:#f92672>=</span>(<span style=color:#e6db74>&#34;print(&#39;hello world&#39;)&#34;</span>,))
</span></span><span style=display:flex><span>t<span style=color:#f92672>.</span>start()
</span></span></code></pre></div><p>要启动一个持续存在的解释器，你可以使用 <code>interpreters.create()</code>，它会返回解释器 ID。这个 ID 可以用于后续的 ``.run_string` 调用：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> _xxsubinterpreters <span style=color:#66d9ef>as</span> interpreters
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>interp_id <span style=color:#f92672>=</span> interpreters<span style=color:#f92672>.</span>create(site<span style=color:#f92672>=</span>site)
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>run_string(interp_id, <span style=color:#e6db74>&#34;print(&#39;hello world&#39;)&#34;</span>)
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>run_string(interp_id, <span style=color:#e6db74>&#34;print(&#39;hello universe&#39;)&#34;</span>)
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>destroy(interp_id)
</span></span></code></pre></div><p>为了共享数据，你可以使用 <code>shared</code> 参数并提供一个带有可共享值（int, float, bool, bytes, str, None, tuple）的字典：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> _xxsubinterpreters <span style=color:#66d9ef>as</span> interpreters
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>interp_id <span style=color:#f92672>=</span> interpreters<span style=color:#f92672>.</span>create(site<span style=color:#f92672>=</span>site)
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>run_string(
</span></span><span style=display:flex><span>    interp_id,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;print(message)&#34;</span>,
</span></span><span style=display:flex><span>    shared<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;hello world!&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>run_string(
</span></span><span style=display:flex><span>    interp_id,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>for message in messages:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    print(message)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;</span>,
</span></span><span style=display:flex><span>    shared<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;messages&#34;</span>: (<span style=color:#e6db74>&#34;hello world!&#34;</span>, <span style=color:#e6db74>&#34;this&#34;</span>, <span style=color:#e6db74>&#34;is&#34;</span>, <span style=color:#e6db74>&#34;me&#34;</span>)
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>destroy(interp_id)
</span></span></code></pre></div><p>一旦解释器开始运行（记住我所说的最好让它们持续运行），你可以使用通道共享数据。通道模块也是 PEP554 的一部分，可以通过秘密导入使用：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> _xxsubinterpreters <span style=color:#66d9ef>as</span> interpreters
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> _xxinterpchannels <span style=color:#66d9ef>as</span> channels
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>interp_id <span style=color:#f92672>=</span> interpreters<span style=color:#f92672>.</span>create(site<span style=color:#f92672>=</span>site)
</span></span><span style=display:flex><span>channel_id <span style=color:#f92672>=</span> channels<span style=color:#f92672>.</span>create()
</span></span><span style=display:flex><span>interpreters<span style=color:#f92672>.</span>run_string(
</span></span><span style=display:flex><span>    interp_id,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>import _xxinterpchannels as channels
</span></span></span><span style=display:flex><span><span style=color:#e6db74>channels.send(&#39;hello!&#39;)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;</span>,
</span></span><span style=display:flex><span>    shared<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;channel_id&#34;</span>: channel_id
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>print(channels<span style=color:#f92672>.</span>recv(channel_id))
</span></span></code></pre></div><h2 id=web-应用中的并行工作机制>Web 应用中的并行工作机制</h2><p>Web 应用中多进程和多线程模型的应用，Python Web 服务器，如用于 Django、Flask、FastAPI 或 Quart 的服务器，使用称为 WSGI 的接口来处理传统 Web 框架，而对于异步框架则使用 ASGI。这些 Web 服务器监听 HTTP 端口上的请求，然后将请求分配给一组工作进程。如果只有一个工作进程，那么当一个用户发出 HTTP 请求时，其他用户必须等待，直到它响应完第一个请求（这也是为什么你不应该将 <code>python manage.py runserver</code> 作为 Web 服务器的原因，因为它只有一个工作进程）。</p><p>Gunicorn 建议的最佳实践是运行多个 Python 进程，由一个主进程协调，并且每个进程都有一个线程池：</p><ul><li>使用多进程启动多个工作进程（通常每个 CPU 核心一个工作进程）</li><li>Web 请求被分配给一个线程池</li></ul><p>这种设计（有时被称为多工作进程-多线程）意味着通过使用多进程，你会为每个 CPU 核心拥有一个 GIL，并且拥有一个线程池来并发处理进入的请求。Uvicorn（异步实现）在此基础上通过使用协程来处理并发，并支持异步框架。</p><p>这种方法有一些缺点。正如我们之前探讨的，线程并不是并行的，所以如果你在单个工作进程中有 2 个线程非常繁忙，Python 无法“移动”或在不同的 CPU 核心上调度该任务。</p><h2 id=应用子解释器到-web-应用中>应用子解释器到 Web 应用中</h2><p>我的目标是用解释器替换多进程作为工作进程的机制。这样做的好处是可以使用高性能的共享内存通道 API 进行工作进程间通信，并且工作进程会更轻量级，占用较少的主机内存（从而留出更多内存和资源来处理请求）。</p><p>另一个相当大胆的目标是编译 CPython 3.13（主分支）并使用 PEP703 中的无 GIL 线程实现，以查看我们是否可以在这个模型中运行无 GIL 线程。我还希望及早识别问题（确实有几个问题）并向上游报告。</p><p>为此，我尝试对 Gunicorn 进行分支操作，用子解释器替换多进程。我发现这将是一项巨大的努力，因为 Gunicorn 确实有“工作进程”的概念，并且在一个称为工作类的接口中对其进行了抽象。然而，它对工作类的能力做了一些假设，而子解释器并不满足这些假设。</p><p>有人在 Mastodon 上建议我检查 Hypercorn，结果发现它非常适合这次测试。Hypercorn 有一个异步工作模块，其中包含一个可以从解释器内部导入的可调用对象。我需要解决的问题是：</p><ol><li>工作进程如何共享套接字？</li><li>如何让一个工作进程干净地关闭（异步事件在解释器间不起作用）？</li></ol><p>于是我遵循了下面的设计：</p><ol><li>创建一个解释器</li><li>创建一个信号通道以发送关闭请求</li><li>子类化 <code>threading.Thread</code> 类并实现一个自定义的 <code>.stop()</code> 方法，该方法向子解释器发送信号</li><li>在一个线程中运行每个子解释器</li><li>将套接字列表转换为元组的元组</li></ol><p>工作类的大致外观如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SubinterpreterWorker</span>(threading<span style=color:#f92672>.</span>Thread):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, number: int, config: Config, sockets: Sockets):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>worker_number <span style=color:#f92672>=</span> number
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>interp <span style=color:#f92672>=</span> interpreters<span style=color:#f92672>.</span>create()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>channel <span style=color:#f92672>=</span> channels<span style=color:#f92672>.</span>create()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>config <span style=color:#f92672>=</span> config <span style=color:#75715e># TODO copy other parameters from config</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>sockets <span style=color:#f92672>=</span> sockets
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__(target<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>run, daemon<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#75715e># Convert insecure sockets to a tuple of tuples because the Sockets type cannot be shared</span>
</span></span><span style=display:flex><span>        insecure_sockets <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> s <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>sockets<span style=color:#f92672>.</span>insecure_sockets:
</span></span><span style=display:flex><span>            insecure_sockets<span style=color:#f92672>.</span>append((int(s<span style=color:#f92672>.</span>family), int(s<span style=color:#f92672>.</span>type), s<span style=color:#f92672>.</span>proto, s<span style=color:#f92672>.</span>fileno()))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        interpreters<span style=color:#f92672>.</span>run_string(
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>interp,
</span></span><span style=display:flex><span>            interpreter_worker,
</span></span><span style=display:flex><span>            shared<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;worker_number&#39;</span>: self<span style=color:#f92672>.</span>worker_number,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;insecure_sockets&#39;</span>: tuple(insecure_sockets),
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;application_path&#39;</span>: self<span style=color:#f92672>.</span>config<span style=color:#f92672>.</span>application_path,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;workers&#39;</span>: self<span style=color:#f92672>.</span>config<span style=color:#f92672>.</span>workers,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;channel_id&#39;</span>: self<span style=color:#f92672>.</span>channel,
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>stop</span>(self):
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Sending stop signal to worker </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(self<span style=color:#f92672>.</span>worker_number))
</span></span><span style=display:flex><span>        channels<span style=color:#f92672>.</span>send(self<span style=color:#f92672>.</span>channel, <span style=color:#e6db74>&#34;stop&#34;</span>)
</span></span></code></pre></div><p>子解释器守护程序代码 (<code>interpreter_worker</code>)：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> sys
</span></span><span style=display:flex><span>sys<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>append(<span style=color:#e6db74>&#39;experiments&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> hypercorn.asyncio.run <span style=color:#f92672>import</span> asyncio_worker
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> hypercorn.config <span style=color:#f92672>import</span> Config, Sockets
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> threading
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> _xxinterpchannels <span style=color:#66d9ef>as</span> channels
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> socket <span style=color:#f92672>import</span> socket
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>shutdown_event <span style=color:#f92672>=</span> asyncio<span style=color:#f92672>.</span>Event()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>wait_for_signal</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>        msg <span style=color:#f92672>=</span> channels<span style=color:#f92672>.</span>recv(channel_id, default<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> msg <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;stop&#34;</span>:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>&#34;接收到停止信号，关闭 </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> &#34;</span><span style=color:#f92672>.</span>format(worker_number))
</span></span><span style=display:flex><span>            shutdown_event<span style=color:#f92672>.</span>set()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;在子解释器 </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> 中启动hypercorn工作进程 &#34;</span><span style=color:#f92672>.</span>format({worker_number}))
</span></span><span style=display:flex><span>_insecure_sockets <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#75715e># 从元组中重建套接字列表</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> s <span style=color:#f92672>in</span> insecure_sockets:
</span></span><span style=display:flex><span>    _insecure_sockets<span style=color:#f92672>.</span>append(socket(<span style=color:#f92672>*</span>s))
</span></span><span style=display:flex><span>hypercorn_sockets <span style=color:#f92672>=</span> Sockets([], _insecure_sockets, [])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>config <span style=color:#f92672>=</span> Config()
</span></span><span style=display:flex><span>config<span style=color:#f92672>.</span>application_path <span style=color:#f92672>=</span> application_path
</span></span><span style=display:flex><span>config<span style=color:#f92672>.</span>workers <span style=color:#f92672>=</span> workers
</span></span><span style=display:flex><span>thread <span style=color:#f92672>=</span> threading<span style=color:#f92672>.</span>Thread(target<span style=color:#f92672>=</span>wait_for_signal)
</span></span><span style=display:flex><span>thread<span style=color:#f92672>.</span>start()
</span></span><span style=display:flex><span>asyncio_worker(config, hypercorn_sockets, shutdown_event<span style=color:#f92672>=</span>shutdown_event)
</span></span></code></pre></div><p>完整代码可在<a class=link href=https://github.com/tonybaloney/subinterpreter-web/blob/master/microweb.py target=_blank rel=noopener>GitHub 上</a>找到。</p><h2 id=发现>发现</h2><p>我的首次尝试还没有在子解释器中实现多线程（除了信号线程外）。我正在构建并测试 CPython 的一个不稳定版本，且处于调试模式。目前尚未准备好进行性能对比测试。</p><p>PEP703 尚未完成。GitHub 上<a class=link href=https://github.com/python/cpython/issues/108219 target=_blank rel=noopener>100 多个待办事项清单</a>大约完成了 50%。只有在完成这个清单后，才能禁用 GIL。</p><p>我还发现了一些问题。首先，Django 根本无法运行。记得在本文前面我提到过，一些 Python C 扩展使用全局共享状态吗？<code>datetime</code>就是这样的模块之一。虽然有一个 issue 是更新它，但目前还未合并。其后果是，如果你从子解释器中导入<code>zoneinfo</code>，它将失败。Django 使用<code>zoneinfo</code>，所以它甚至无法启动。</p><p>我在一个非常简陋的 FastAPI 和 Flask 应用程序上有更多的运气。我能够启动 2、4 和 10 个工作进程的设置。我对 FastAPI 和 Flask 应用程序进行了一些基准测试，以查看它们如何处理 10,000 个请求，同时并发量为 20。两者都表现出色，我的所有 CPU 核心都在忙碌工作。</p><p>我感到非常惊讶，因为我根本没有期望它会工作，因为子解释器是如此新颖，且 Python 生态系统还没有对它们进行测试。下一步是测试更复杂的 Web 应用程序，继续报告崩溃和问题，然后让这个 Web 工作进程稳定到足以进行基准测试的状态。</p><p>然后，我可能会为 Hypercorn 提交一个 PR，以便于适配明年发布的 Python 3.13。</p><p><img src=../../../2023/11/python-312-sub-interpreters/four-snakes-cartoon.jpeg width=1024 height=1024 srcset="../../../2023/11/python-312-sub-interpreters/four-snakes-cartoon_huf677ab5284dc3059c291ae31652dfe1d_131137_480x0_resize_q75_box.jpeg 480w, ../../../2023/11/python-312-sub-interpreters/four-snakes-cartoon_huf677ab5284dc3059c291ae31652dfe1d_131137_1024x0_resize_q75_box.jpeg 1024w" loading=lazy class=gallery-image data-flex-grow=100 data-flex-basis=240px></p></section><footer class=article-footer><section class=article-tags><a href=../../../tags/software-architecture/>Software Architecture</a>
<a href=../../../tags/python/>Python</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=../../../2023/01/twirp-first-step/><div class=article-image><img src=../../../2023/01/twirp-first-step/cover.7105b701d75203ea09b83fa4e43ca7d8_hu4d2397f242cbaad1c9e92197e5120b6d_93873_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post Twirp初相识" data-key=twirp-first-step data-hash="md5-cQW3AddSA+oJuD+k5Dyn2A=="></div><div class=article-details><h2 class=article-title>Twirp初相识</h2></div></a></article><article class=has-image><a href=../../../2023/01/twirp-hooks-and-interceptors/><div class=article-image><img src=../../../2023/01/twirp-hooks-and-interceptors/cover.7105b701d75203ea09b83fa4e43ca7d8_hu4d2397f242cbaad1c9e92197e5120b6d_93873_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post Twirp基本概念：Hooks和Interceptors" data-key=twirp-hooks-and-Interceptors data-hash="md5-cQW3AddSA+oJuD+k5Dyn2A=="></div><div class=article-details><h2 class=article-title>Twirp基本概念：Hooks和Interceptors</h2></div></a></article><article class=has-image><a href=../../../2023/01/something-happend-in-2022-1/><div class=article-image><img src=../../../2023/01/something-happend-in-2022-1/cover.eb1cf3d7db27c1fa048f8f570f779b15_hue027cc0fcb1ab7e4133c399c67e42055_143933_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post 去年的一点小工作(1)：从BFF谈起" data-key=something-happend-in-2022-1 data-hash="md5-6xzz19snwfoEj49XD3ebFQ=="></div><div class=article-details><h2 class=article-title>去年的一点小工作(1)：从BFF谈起</h2></div></a></article><article class=has-image><a href=../../../2021/08/common-anti-patterns-in-go-web-applications/><div class=article-image><img src=https://www.4async.com/2020/02/2020-02-16-moving-towards-domain-driven-design-in-go/cover_huea63e6370dcf0c375755d886a5d0b9c6_97708_1600x0_resize_q75_box.jpg loading=lazy data-key=common-anti-patterns-in-go-web-applications data-hash=https://www.4async.com/2020/02/2020-02-16-moving-towards-domain-driven-design-in-go/cover_huea63e6370dcf0c375755d886a5d0b9c6_97708_1600x0_resize_q75_box.jpg></div><div class=article-details><h2 class=article-title>Go Web应用中常见的反模式</h2></div></a></article><article class=has-image><a href=../../../2021/07/introducing-event-modeling/><div class=article-image><img src=../../../2021/07/introducing-event-modeling/_hucf7c873ea7f3b2f557ada81568c30cdb_177241_240c37b86f28be968c6b0bb34095736b.jpg width=250 height=150 loading=lazy alt="Featured image of post 什么是事件建模Event Modeling?" data-key=introducing-event-modeling data-hash="md5-r46sGJr30VU2AdrzIX2KFw=="></div><div class=article-details><h2 class=article-title>什么是事件建模Event Modeling?</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//s1mbily.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2013 -
2024 ipfans's Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.22.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=../../../ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>